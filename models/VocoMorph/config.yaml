experiment: "VocoMorphBase"
notes: "Neural Vocal Modulator V1.\
   TCN (Temporal Convolutional Network) backbone & FiLM (Feature-wise Linear Modulation)\
   layers are used to condition an audio on an Embedding Vector"
# ------------------------------------------------------------------------------------------------------------------------------ #
config:
  # ------------------------------------------------------------ #
  seed: 13

  data:
    num_workers: 1
    pin_memory: true
    drop_last: true

    channels: &var_num_channels 1 # mono/stereo
    sample_rate: &var_sample_rate 16_000
    n_mels: &var_n_mels 80
    n_fft: &var_n_fft 512
    win_length: &var_win_length 512
    hop_length: &var_hop_length 128

    # the chunk of audio the model processes at a time
    frame_length: &var_frame_length 800 # 50ms at 16k
    # max audio length during training
    max_length: 160_000 # 10 sec at 16k sr, -1 if you dont want to trim

    dataset: "timit"

    datalists:
      train:
        batch_size: 16
        path: "data/metadata/timit_train.csv"
      valid:
        batch_size: 16
        path: "data/metadata/timit_valid.csv"
      test: 
        batch_size: 1
        path: "data/metadata/timit_test.csv"

    effects:
      &var_modulation_effects [
        "identity_transform",
        "apply_pitch_shift",
        "apply_radio_effect",
        "apply_robotic_effect",
        "apply_scifi_effect",
      ]
  # ------------------------------------------------------------ #
  model:
      num_channels: *var_num_channels
      chunk_size: *var_frame_length
      overlap: 0
      num_blocks: 2
  
      module_stft:
        output_length: *var_frame_length
        n_fft: *var_n_fft
        hop_length: *var_hop_length
        win_length: *var_win_length

      module_effect_encoder:
        effects: *var_modulation_effects
        embedding_dim: &var_embedding_dim 64

      module_subnet:
        input_channels: *var_num_channels
        hidden_channels: 128
        kernel_size: [3,3]

      module_film:
        input_dim: *var_embedding_dim
        output_dim: 257
  # ------------------------------------------------------------ #
  # loss functions
  criterion:
    name: [
        # "STFTLoss",
        "MultiResolutionSTFTLoss",
        # "VocalModulationLoss",
      ]
    STFTLoss:
      n_fft: *var_n_fft
      hop_length: *var_hop_length
      win_length: *var_win_length
    MultiResolutionSTFTLoss:
      alpha: 0.5
      beta: 0.5
      # n_fft, hop_length, win_length
      resolutions: [
      # Good frequency resolution, medium time resolution
          [1024, 1024, 256], 
      # Excellent frequency resolution, poor time resolution
          [2048, 2048, 512], 
      # Moderate frequency resolution, good time resolution
          [512, 512, 128], 
        ]
    MelSpecLoss:
      alpha: 0.5
      beta: 0.5
      sample_rate: *var_sample_rate
      n_mels: *var_n_mels
      n_fft: *var_n_fft
      hop_length: *var_hop_length
      win_length: *var_win_length

    VocalModulationLoss:
      alpha: 0.3
      beta: 0.3
      gamma: 0.3
      sample_rate: *var_sample_rate
      n_mels: *var_n_mels
      n_fft: *var_n_fft
      hop_length: *var_hop_length
      win_length: *var_win_length
  # ------------------------------------------------------------ #
  optimizer:
    name: ["AdamW"]
    AdamW:
      lr: 1.0e-3
      weight_decay: 1.0e-4
  # ------------------------------------------------------------ #
  # LR scheduler
  scheduler:
    name: ["ReduceLROnPlateau", "WarmupConstantSchedule"]
    ReduceLROnPlateau:
      mode: "min"
      min_lr: 1.0e-10
      factor: 0.8
      patience: 2
    WarmupConstantSchedule:
      warmup_steps: 1000
    # ------------------------------------------------------------ #
  # metrics to evaluate the model on
  metrics:
    name: ["MeanSquaredError"]
  # ------------------------------------------------------------ #
  trainer:
    max_epoch: 100
    gpuid: [0]
    clip_norm: 5
    start_scheduling: 50
    test_epochs: [20, 50, 100]
    precision: "fp16"

  checkpointer:
    save_interval: 5 # num epochs to save checkpoint
    save_best: true
    keep_last_n: null # false or int
