experiment: "VocoMorphUnet"
notes: "Neural Vocal Modulator V3
  UNet & FiLM (Feature-wise Linear Modulation) layers
  are used to condition an audio on an Embedding Vector
  Input length must be divisible by 2^number of unet blocks.
  otherwise upsampling won't restore original size.
  "
# ------------------------------------------------------------------------------------------------------------------------------ #
config:
  # ------------------------------------------------------------ #
  seed: 13

  data:
    num_workers: 5
    pin_memory: true
    drop_last: true

    channels: &var_num_channels 1 # mono/stereo
    sample_rate: 16000
    n_mels: 80
    n_fft: 512
    win_length: 512
    hop_length: 128

    # the chunk of audio the model processes at a time
    frame_length: &var_frame_length 4096 # 256 ms at 16k
    # max audio length during training
    max_length: 160000 # 10 sec at 16k sr, -1 if you dont want to trim

    dataset: "timit"

    datalists:
      train:
        batch_size: 16
        path: "data/metadata/timit_train.csv"
      valid:
        batch_size: 16
        path: "data/metadata/timit_valid.csv"
      test:
        batch_size: 1
        path: "data/metadata/timit_test.csv"

    effects:
      [
        "identity_transform",
        "apply_pitch_shift",
        "apply_radio_effect",
        "apply_robotic_effect",
        "apply_scifi_effect",
      ]
  # ------------------------------------------------------------ #
  model:
    num_channels: *var_num_channels
    chunk_size: *var_frame_length
    overlap: 0
    embedding_dim: 32
    num_effects: 5
    encoder_filters: [32, 64, 128, 256, 512] # 5 levels
    bottleneck_filters: [1024, 1024]
    decoder_filters: [512, 256, 128, 64, 32] # 5 levels
    kernel_size: 3
    padding: 1
  # ------------------------------------------------------------ #
  # loss functions
  criterions:
    name: ["MSELoss"]
  # ------------------------------------------------------------ #
  optimizers:
    name: ["AdamW"]
    AdamW:
      lr: 1.0e-3
      betas: [0.9, 0.999]
      weight_decay: 1.0e-4
  # ------------------------------------------------------------ #
  # LR scheduler
  schedulers:
    name: ["ReduceLROnPlateau"]
    ReduceLROnPlateau:
      mode: "min"
      min_lr: 1.0e-10
      factor: 0.8
      patience: 2
    WarmupConstantSchedule:
      warmup_steps: 1000
    # ------------------------------------------------------------ #
  # metrics to evaluate the model on
  metrics:
    name: []
  # ------------------------------------------------------------ #
  trainer:
    max_epoch: 100
    gpuid: [0]
    clip_norm: 5
    start_scheduling: 50
    test_epochs: [20, 50, 100]
    precision: "fp16"

  checkpointer:
    save_interval: 5 # num epochs to save checkpoint
    save_best: true
    keep_last_n: null # false or int
